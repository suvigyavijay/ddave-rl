{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from env import DangerousDaveEnv\n",
    "import time, os\n",
    "from custom_cnn import policy_kwargs\n",
    "import torch\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppo_test tensorboard_log/ppo_test\n",
      "(1, 11, 19)\n",
      "Box(0, 255, (1, 11, 19), uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: cHRM chunk does not match sRGB\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "\n",
    "# Manual assignment of arguments (replace with your desired values or use ipywidgets for interactivity)\n",
    "train = False  # equivalent to --train in argparse\n",
    "evaluate = True  # equivalent to --evaluate in argparse\n",
    "model_name = \"ppo_test\"  # manually specify or generate a name\n",
    "env_rep_type = 'text'  # 'text' or 'image'\n",
    "model_type = 'PPO'  # 'DQN', 'RND', or 'PPO'\n",
    "retrain = False  # equivalent to --retrain in argparse\n",
    "\n",
    "# Your existing logic below\n",
    "checkpoint_timestamp = int(time.time())\n",
    "if not model_name:\n",
    "    model_name = \"checkpoints/dqn_ddave_{}\".format(checkpoint_timestamp)\n",
    "\n",
    "tensorboard_log = f\"tensorboard_log/{model_name}\"\n",
    "tensorboard_log_run_name = '0'\n",
    "print(model_name,tensorboard_log)\n",
    "# Create the DangerousDaveEnv environment\n",
    "env = DangerousDaveEnv(render_mode=\"human\", env_rep_type=env_rep_type)\n",
    "\n",
    "\n",
    "total_timesteps=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (terminated \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[1;32m     45\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 46\u001b[0m     obs, rewards, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/Documents/UB_SPRING_24/CSE546/ddave-rl/env.py:137\u001b[0m, in \u001b[0;36mDangerousDaveEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclock\u001b[38;5;241m.\u001b[39mtick()\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Return observation, reward, done, info\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# print(\"Time:\", self.episode_clock)\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reward(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mended_game, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_clock \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m, {}\n",
      "File \u001b[0;32m~/Documents/UB_SPRING_24/CSE546/ddave-rl/env.py:286\u001b[0m, in \u001b[0;36mDangerousDaveEnv._get_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# Normalize the game data if needed\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# game_data = game_data / 255.0\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_rep_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 286\u001b[0m     game_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m game_data\n",
      "File \u001b[0;32m~/Documents/UB_SPRING_24/CSE546/ddave-rl/env.py:254\u001b[0m, in \u001b[0;36mDangerousDaveEnv._get_text_representation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m map_text_rep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line_index,node_line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLevel\u001b[38;5;241m.\u001b[39mnode_matrix):\n\u001b[0;32m--> 254\u001b[0m     map_text_rep\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_enc\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetId\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnode_line\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    256\u001b[0m map_text_rep \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(map_text_rep,dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/UB_SPRING_24/CSE546/ddave-rl/env.py:254\u001b[0m, in \u001b[0;36mDangerousDaveEnv._get_text_representation.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    252\u001b[0m map_text_rep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line_index,node_line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLevel\u001b[38;5;241m.\u001b[39mnode_matrix):\n\u001b[0;32m--> 254\u001b[0m     map_text_rep\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_enc\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetId\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,node_line[:\u001b[38;5;241m19\u001b[39m]))))\n\u001b[1;32m    256\u001b[0m map_text_rep \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(map_text_rep,dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/UB_SPRING_24/CSE546/ddave-rl/ddave/utils.py:663\u001b[0m, in \u001b[0;36mTile.getId\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgfx_id \u001b[38;5;241m=\u001b[39m gfx_id\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: ErrorInvalidValue()\n\u001b[0;32m--> 663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetId\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetGfxId\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if model_type == 'DQN':\n",
    "    if train:\n",
    "        # Define and train the DQN agent\n",
    "        if retrain:\n",
    "            model = DQN.load(\"checkpoints/{}\".format(model_name),tensorboard_log=tensorboard_log)\n",
    "            model.exploration_fraction  = 0.7\n",
    "            model.set_env(env)\n",
    "        else:\n",
    "            model = DQN(\"CnnPolicy\", env, verbose=1, batch_size=256, policy_kwargs=policy_kwargs,\n",
    "                        learning_starts=1000, exploration_fraction=0.5, exploration_final_eps=0.01, device=device,\n",
    "                        target_update_interval=5000, buffer_size=100000,tensorboard_log=tensorboard_log)\n",
    "\n",
    "        model.learn(total_timesteps=total_timesteps, progress_bar=True,tb_log_name=tensorboard_log_run_name,log_interval=1)\n",
    "        \n",
    "        # Save the trained model if desired\n",
    "        model.save(\"checkpoints/{}\".format(model_name))\n",
    "\n",
    "    if evaluate:\n",
    "        # Evaluate the trained model\n",
    "        model = DQN.load(\"checkpoints/{}\".format(model_name), env=env,tensorboard_log=tensorboard_log)\n",
    "\n",
    "elif model_type == 'PPO':\n",
    "    if train:\n",
    "        # Define and train the PPO agent\n",
    "        if retrain:\n",
    "            model = PPO.load(\"checkpoints/{}\".format(model_name), env=env,tensorboard_log=tensorboard_log)\n",
    "        else:\n",
    "            model = PPO(\"CnnPolicy\", env, verbose=1, batch_size=256, policy_kwargs=policy_kwargs, device=device,\n",
    "                        tensorboard_log=tensorboard_log,ent_coef=0.01,vf_coef=1)\n",
    "\n",
    "        model.learn(total_timesteps=total_timesteps, progress_bar=True,tb_log_name=tensorboard_log_run_name,log_interval=1)\n",
    "        \n",
    "        # Save the trained model if desired\n",
    "        model.save(\"checkpoints/{}\".format(model_name))\n",
    "\n",
    "    if evaluate:\n",
    "        # Evaluate the trained model\n",
    "        model = PPO.load(\"checkpoints/{}\".format(model_name), env=env,tensorboard_log=tensorboard_log)\n",
    "\n",
    "if evaluate:\n",
    "    obs, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    while not (terminated or truncated):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, rewards, terminated, truncated, info = env.step(action)\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = tensorboard_log+'/'+tensorboard_log_run_name +'_5/'\n",
    "logfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir {logfile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_ddave_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
